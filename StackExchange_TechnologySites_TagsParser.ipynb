{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6cd94a7-aa3e-4724-a87c-46c7b2edda0c",
   "metadata": {},
   "source": [
    "<h1>Code Snippets for Parsing the Tags Datasets of Technology Related Stack Exchange Sites (D1 and D2)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4cdc4c-5faa-4702-8353-02629ed1e75b",
   "metadata": {},
   "source": [
    "<p><b>Step1:</b> <u>Identifying the technology related Stack Exchange based sites from the <a href='https://stackexchange.com/sites#technology-oldest'>official site</a> of Stack Exchange. </u>At the time of writing, Stack Exchange Network hosts 182 sites out of which 77 are listed under Technology tab including Stack Overflow and Software Recommendations. We excluded the Russian, Japanese, \n",
    "Spanish and Portuguese variants of Stack Overflow and the Meta Stack Exchang \r\n",
    "which deals with meta-discussions related to Stack Exchange based Q&A Websitesand considered the remaining 71 sites as technology related sites., </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa140f5-c697-4c32-8fbd-f761531371b3",
   "metadata": {},
   "source": [
    "<p><b>Step2:</b> <u>Downloading the complete set of Tags used on each site from the  <a href='https://data.stackexchange.com/stackoverflow/query/new'>Stack Exchange Data Explorer (SEDE)</a></u>The SEDE interface allows its users to retrieve data using SQL queries from any of its sites. We selected the technology related sites one by one and used the following simple SQL query to retrieve the set of tags corresponding to the selected site.   The user interface allows users to download data returned through their queries in CSV format so we saved it. The Stack Overflow tags were not downloaded as we considered them from the complete data dump processed as part of D3.</p> "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6aa547a8-e264-4301-aeff-fbd07a21caa4",
   "metadata": {},
   "source": [
    "Select * from Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f57e31-b06b-411e-b251-188e9f86ce9b",
   "metadata": {},
   "source": [
    "<p><b>Step3:</b> <u>Saving the datasets in database tables for further processing.</u> Instead of manually importing each CSV file for the 70 technology related sites, we used the following code snippet to create the corresponding tables for each of the sites and then insert data from CSV files to the database tables. <i>Don't forget to create database <code>StackExchangeTagsDb_July2024</code> using SSMS before executing this snippet.</i></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19c99f-2ac4-4bed-b386-1fcb07ac7327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import glob\n",
    "import os\n",
    "server = 'DESKTOP-DEK23E9'\n",
    "database = 'StackExchangeTagsDb_July2024' \n",
    "\n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';')\n",
    "cursor = cnxn.cursor()\n",
    "\n",
    "tags_directory_path =r'E:\\\\Dataset_2024\\\\stackexchange-Tags-July2024\\\\stackexchange-Tags-July2024\\\\'\n",
    "\n",
    "for filename in glob.glob(os.path.join(tags_directory_path, '*')):\n",
    "\n",
    "    print(filename)\n",
    "    head, tail = os.path.split(filename)\n",
    "    tail = tail.replace(\" \",\"\")\n",
    "    tail = tail.replace(\".csv\",\"\")\n",
    "    tail = tail.replace(\"-\",\"\")\n",
    "    tail = tail.split(\"(\")[0]\n",
    "     \n",
    "    print(tail)\n",
    "    query=\"CREATE TABLE {} (AutoIdPK int Identity(1,1),Id int, TagName nvarchar(35), Count int, ExcerptPostId int,WikiPostId int, IsRequired bit,IsModeratorOnly bit)\".format(tail)    \n",
    "    print(query)\n",
    "    cursor.execute(query)\n",
    "    print(\"Created table in database\")\n",
    "    tags_df = pd.read_csv(filename)  \n",
    "    tags_df = tags_df.fillna(0) \n",
    "    print(tags_df.head())\n",
    "    \n",
    "    columnnames= list(tags_df.columns.values)\n",
    "    columns=','.join(columnnames)\n",
    "\n",
    "    query = \"insert into {} ({}) values ({})\".format(tail, columns, \"?,\"*(len(columnnames)-1)+\"?\")\n",
    "    print(query)\n",
    "    cursor.executemany(query, tags_df.values.tolist())\n",
    "    print(\"Added in database\")\n",
    "    \n",
    "cursor.commit()\n",
    "print(\"Process completed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3824d8c3-a707-4857-ba27-d5fd662d01e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1f79f-0bb8-45b8-9e05-742c3a164816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
